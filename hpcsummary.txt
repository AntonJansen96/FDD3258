Organizational ################################################################

login
    kinit --forwardable ajansen@NADA.KTH.SE         # Create Kerberos ticket.
    ssh -X ajansen@beskow.pdc.kth.se                # Login.
data
    Two file systems: AFS (Andrew File System) and Lustre.
    You login to AFS, but all files for Beskow should be stored on Lustre.

    Upon login, you are at:     /afs/pdc.kth.se/home/a/ajansen
                                Store backups of important files here.
    
    FS avail to compute nodes:  /cfs/klemming/nobackup/a/ajansen
                                /cfs/klemming/scratch/a/ajansen     (temp)
compiling/running
    salloc --nodes=1 -t 01:00:00 -A main.cc     # allocate interactive node.
    srun -n 1 ./main                            # launch program on said node.

jobscript
    #!/bin/bash

    # The name of the script is myjob
    #SBATCH -J myjob
    # Only 1 hour wall-clock time will be given to this job
    #SBATCH -t 1:00:00
    #SBATCH -A edu20.FDD3258
    # Number of nodes
    #SBATCH --nodes=1
    #SBATCH -e error_file.e

    # Run the executable file 
    # and write the output into my_output_file
    srun -n 1 ./hello.out > hello_output    

Module1 ########################################################################

benchmarks
    Slides discuss some scientific problems often used to bench clusters.
    Not relevant to me.
modeling sparse matrix-vectory multiplication
    Clock rate-based performance analysis often not useful.
    Cache design important.
    Still nothing really relevant.
more on cache memories
    Cache memory contains a copy of the main memory data.
    Cache memory is faster but consumes more space and power.
    Cache items are accessed by their address in main memory.

    memory locality
        L1      few cycles
        L2      ~ 10 cycles
        RAM     ~ 250 cycles
        Remote  ~2500-5000 cycles

    Data moves between RAM and cache in groups (chunks) called CACHE LINES.
    Size typically 64-128 bytes.
measuring performance
    All about clocks a la my C++ class.
matrix transpose
    Example of cache related performance effects using a matrix transpose.

more on caches II and III (optional)
    If a load/store from CPU cannot be satisfied from cache, a CACHE MISS occurs.

    1.  compulsory      on first access to a cache, block must be brought into 
                        cache (also called a cold start or first reference miss).
    2.  capacity        occur because lines are being discarded.
    3.  conflict        several lines are mapped to the same set (collision miss).

    Cache misses can be monitored using the perf tool.
    Perf is a performance monitoring and analyzing tool in linux.
    
instruction execution and pipelining
    About pipelining (concurrent execution of instructions)

vectorization // good
    -Vectorization is a compiler optimization, making use of CPU parallelism.
    -Vectors operator on 128 bit (16 byte) operands:
        -4 floats/ints.
        -2 doubles.
    -For g++, use "-O2 -ftree-vectorize" or simply "-O3".
    -To check, use "-fopt-info-vec -fopt-info-vec-missed".

Module2 ########################################################################

discussing speed-up
    -For parallel applications, speedup is defined as T_1/T_n.
     T_1 is time using one core etc.
    -Speedup CAN be greater then 1 (superlinear) in certain case.
    -Amdahl's law.
Moore's law and speed-up
    Usually cast as X doubles every 18-24 months.
        X:  Computer performance
            CPU Clock speed
            The number of transitors per chip at constant cost

    (end of) Dennard scaling
        -Explains why clock speeds have not increased with shrinking transistors.
        -As transistors get smaller, power density increases because these don't
         scale with size --> creating of a "power wall" (since ~2006).
threads
    A thread is a basic unit of processor utilization.
  
        -Within a process, all memory shared.
        -Each "thread" executes "normal" code.

        Can be:
            -Library-based (invoke a routine in a separate thread) (pthreads).
            -Separate enhancements to existing languages (OpenMP, CUDA).
            -Within the language itself (Java, C11).

        How to fix synchronization issues:
            -Need to impose order of memory updates
                -OpenMP has FLUSH
                -Memory barriers

            -Often, need to ensure updates happen atomically (all or nothing).

        Limits to performance
            -Threads SHARE memory resources.
            -Therefore, performance is roughly linear until bandwith is saturated.

OpenMP
    Open Multi-Processing (OpenMP) is an API that supports shared-memory
    multiprocessing programming in C, C++, and Fortran.
    -OpenMP is mostly a compiler technology.
    -OpenMP directives are issued to the compiler using "#pragma".

    OpenMP library                  #include <omp.h>
        modify/check #threads       omp_set_num_threads()
                                    omp_get_thread_num()
                                    omp_get_num_threads()
                                    omp_get_max_threads()
        check if in parallel        omp_in_parallel()
        dynamically vary #threads   omp_set_dynamic()
                                    omp_get_dynamic()
        check #processes            omp_num_procs()

    environment variables (bash)
        Set default #threads    OMP_NUM_THREADS     int_literal 
        Set process binding     OMP_PROC_BIND       true | false
        Control loop iters      OMP_SCHEDULE        schedule [chunk_size]

        To set an env var       export <var> = <val>            

    ---------------------------------------------------------------------------

    syntax
        -Mostly compiler directives (#pragma omp ... [clause]).
        -Some functions and types (#include <omp.h>).
        -Most apply to a block of code.
    
    details
        -We can either execute general parallel regions or parallel loops.
        -Special case for loops.
        -Several ways to manage thread coordination, including:
            -Maste regions
            -Locks
        -Memory model for share data
            -Flush
    
    parallel_region
        # pragma omp parallel
        {
            // ... code executed by each thread.
        }

        -Effectivel a "fork" at the beginning and a "join" at the end.
        -Variables allocated before entering the parallel region are shared.

    reduction
